{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import Scalagram\n",
    "from Scalagram import Scalagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"/Users/lucasgover/Desktop/Wavelet-Transform/Data/SwainsonCut.wav\"\n",
    "sg = Scalagram(file_location)\n",
    "image = sg.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "original code from: https://github.com/FLming/CRNN.tf2/blob/master/crnn/models.py\n",
    "The original feature extraction structure from CRNN paper.\n",
    "Related paper: https://ieeexplore.ieee.org/abstract/document/7801919\n",
    "\"\"\"\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def vgg_style(x):\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        64, 3, padding='same', activation='relu', name='conv1')(x)\n",
    "    x = layers.MaxPool1D(pool_size=2, padding='same', name='pool1')(x)\n",
    "\n",
    "    x = layers.Conv1D(\n",
    "        128, 3, padding='same', activation='relu', name='conv2')(x)\n",
    "    x = layers.MaxPool1D(pool_size=2, padding='same', name='pool2')(x)\n",
    "\n",
    "    x = layers.Conv1D(256, 3, padding='same', use_bias=False, name='conv3')(x)\n",
    "    x = layers.BatchNormalization(name='bn3')(x)\n",
    "    x = layers.Activation('relu', name='relu3')(x)\n",
    "    x = layers.Conv1D(\n",
    "        256, 3, padding='same', activation='relu', name='conv4')(x)\n",
    "    x = layers.MaxPool1D(\n",
    "        pool_size=2, strides=(1), padding='same', name='pool4')(x)\n",
    "\n",
    "    x = layers.Conv1D(512, 3, padding='same', use_bias=False, name='conv5')(x)\n",
    "    x = layers.BatchNormalization(name='bn5')(x)\n",
    "    x = layers.Activation('relu', name='relu5')(x)\n",
    "    x = layers.Conv1D(\n",
    "        512, 3, padding='same', activation='relu', name='conv6')(x)\n",
    "    x = layers.MaxPool1D(\n",
    "        pool_size=2, strides=(1), padding='same', name='pool6')(x)\n",
    "\n",
    "    x = layers.Conv1D(512, 2, use_bias=False, name='conv7')(x)\n",
    "    x = layers.BatchNormalization(name='bn7')(x)\n",
    "    x = layers.Activation('relu', name='relu7')(x)\n",
    "\n",
    "    x = layers.Flatten(name='flatten1')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def build_model(num_classes,\n",
    "                weight=None,\n",
    "                preprocess=None,\n",
    "                postprocess=None,\n",
    "                img_shape=(32, None, 3),\n",
    "                model_name='crnn'):\n",
    "    x = img_input = keras.Input(shape=img_shape)\n",
    "    if preprocess is not None:\n",
    "        x = preprocess(x)\n",
    "    \n",
    "    x = vgg_style(x)\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(units=256, return_sequences=True), name='bi_lstm1')(x)\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(units=256, return_sequences=True), name='bi_lstm2')(x)\n",
    "    x = layers.Dense(units=num_classes, name='logits')(x)\n",
    "    \n",
    "    if postprocess is not None:\n",
    "        x = postprocess(x)\n",
    "\n",
    "    model = keras.Model(inputs=img_input, outputs=x, name=model_name)\n",
    "    if weight is not None:\n",
    "        model.load_weights(weight, by_name=True, skip_mismatch=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165468"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_image = np.asarray(list(map(lambda a:a.flatten(),image)))\n",
    "len(flattened_image)\n",
    "rev_flatten = np.asarray(list(map(lambda a:a.reshape(len(image[0]),2),flattened_image)))\n",
    "len(rev_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = build_model(num_classes=len(flattened_image[0]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m build_model(\u001b[39mlen\u001b[39;49m(flattened_image[\u001b[39m0\u001b[39;49m]),img_shape\u001b[39m=\u001b[39;49mimage[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape)\n",
      "\u001b[1;32m/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb Cell 7\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(num_classes, weight, preprocess, postprocess, img_shape, model_name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mif\u001b[39;00m preprocess \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     x \u001b[39m=\u001b[39m preprocess(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m x \u001b[39m=\u001b[39m vgg_style(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mBidirectional(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     layers\u001b[39m.\u001b[39mLSTM(units\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbi_lstm1\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mBidirectional(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     layers\u001b[39m.\u001b[39mLSTM(units\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbi_lstm2\u001b[39m\u001b[39m'\u001b[39m)(x)\n",
      "\u001b[1;32m/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb Cell 7\u001b[0m in \u001b[0;36mvgg_style\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mBatchNormalization(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbn7\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mActivation(\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu7\u001b[39m\u001b[39m'\u001b[39m)(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mReshape((\u001b[39m9216\u001b[39;49m), name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreshape7\u001b[39;49m\u001b[39m'\u001b[39;49m)(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/layers/core/reshape.py:66\u001b[0m, in \u001b[0;36mReshape.__init__\u001b[0;34m(self, target_shape, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m\"\"\"Creates a `tf.keras.layers.Reshape`  layer instance.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m  **kwargs: Any additional layer keyword arguments.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39msuper\u001b[39m(Reshape, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_shape \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(target_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "model = build_model(len(flattened_image[0]),img_shape=image[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.95),\n",
    "                  loss=\"mean_squared_error\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"crnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 76, 2)]           0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 76, 64)            448       \n",
      "                                                                 \n",
      " pool1 (MaxPooling1D)        (None, 38, 64)            0         \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 38, 128)           24704     \n",
      "                                                                 \n",
      " pool2 (MaxPooling1D)        (None, 19, 128)           0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 19, 256)           98304     \n",
      "                                                                 \n",
      " bn3 (BatchNormalization)    (None, 19, 256)           1024      \n",
      "                                                                 \n",
      " relu3 (Activation)          (None, 19, 256)           0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 19, 256)           196864    \n",
      "                                                                 \n",
      " pool4 (MaxPooling1D)        (None, 19, 256)           0         \n",
      "                                                                 \n",
      " conv5 (Conv1D)              (None, 19, 512)           393216    \n",
      "                                                                 \n",
      " bn5 (BatchNormalization)    (None, 19, 512)           2048      \n",
      "                                                                 \n",
      " relu5 (Activation)          (None, 19, 512)           0         \n",
      "                                                                 \n",
      " conv6 (Conv1D)              (None, 19, 512)           786944    \n",
      "                                                                 \n",
      " pool6 (MaxPooling1D)        (None, 19, 512)           0         \n",
      "                                                                 \n",
      " conv7 (Conv1D)              (None, 18, 512)           524288    \n",
      "                                                                 \n",
      " bn7 (BatchNormalization)    (None, 18, 512)           2048      \n",
      "                                                                 \n",
      " relu7 (Activation)          (None, 18, 512)           0         \n",
      "                                                                 \n",
      " reshape7 (Reshape)          (None, 18, 512)           0         \n",
      "                                                                 \n",
      " bi_lstm1 (Bidirectional)    (None, 18, 512)           1574912   \n",
      "                                                                 \n",
      " bi_lstm2 (Bidirectional)    (None, 18, 512)           1574912   \n",
      "                                                                 \n",
      " logits (Dense)              (None, 18, 152)           77976     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,257,688\n",
      "Trainable params: 5,255,128\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165468, 152)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 459, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/metrics.py\", line 178, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/metrics.py\", line 729, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/metrics.py\", line 4086, in sparse_categorical_accuracy\n        return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n\n    ValueError: Dimensions must be equal, but are 152 and 18 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](IteratorGetNext:1, Cast_1)' with input shapes: [?,152], [?,18].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lucasgover/Desktop/Wavelet-Transform/src/RNN_Wavelet.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(image[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], flattened_image[\u001b[39m1\u001b[39;49m:],epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 459, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/metrics.py\", line 178, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/metrics.py\", line 729, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/metrics.py\", line 4086, in sparse_categorical_accuracy\n        return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n\n    ValueError: Dimensions must be equal, but are 152 and 18 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](IteratorGetNext:1, Cast_1)' with input shapes: [?,152], [?,18].\n"
     ]
    }
   ],
   "source": [
    "model.fit(image[:-1], flattened_image[1:],epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
