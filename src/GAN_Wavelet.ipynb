{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import Scalagram\n",
    "from Scalagram import Scalagram\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"/Users/lucasgover/Desktop/Wavelet-Transform/Data/SwainsonCut.wav\"\n",
    "sg = Scalagram(file_location)\n",
    "image = sg.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_stupid_mnist import get_stupid_mnist\n",
    "X = get_stupid_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  3  18]\n",
      "  [ 18  18]\n",
      "  [126 136]\n",
      "  [175  26]\n",
      "  [166 255]\n",
      "  [247 127]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 30  36]\n",
      "  [ 94 154]\n",
      "  [170 253]\n",
      "  [253 253]\n",
      "  [253 253]\n",
      "  [225 172]\n",
      "  [253 242]\n",
      "  [195  64]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  49]\n",
      "  [238 253]\n",
      "  [253 253]\n",
      "  [253 253]\n",
      "  [253 253]\n",
      "  [253 251]\n",
      "  [ 93  82]\n",
      "  [ 82  56]\n",
      "  [ 39   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  18]\n",
      "  [219 253]\n",
      "  [253 253]\n",
      "  [253 253]\n",
      "  [198 182]\n",
      "  [247 241]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 80 156]\n",
      "  [107 253]\n",
      "  [253 205]\n",
      "  [ 11   0]\n",
      "  [ 43 154]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  14]\n",
      "  [  1 154]\n",
      "  [253  90]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0 139]\n",
      "  [253 190]\n",
      "  [  2   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  11]\n",
      "  [190 253]\n",
      "  [ 70   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 35 241]\n",
      "  [225 160]\n",
      "  [108   1]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  81]\n",
      "  [240 253]\n",
      "  [253 119]\n",
      "  [ 25   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 45 186]\n",
      "  [253 253]\n",
      "  [150  27]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  16]\n",
      "  [ 93 252]\n",
      "  [253 187]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0 249]\n",
      "  [253 249]\n",
      "  [ 64   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 46 130]\n",
      "  [183 253]\n",
      "  [253 207]\n",
      "  [  2   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 39 148]\n",
      "  [229 253]\n",
      "  [253 253]\n",
      "  [250 182]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 24 114]\n",
      "  [221 253]\n",
      "  [253 253]\n",
      "  [253 201]\n",
      "  [ 78   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 23  66]\n",
      "  [213 253]\n",
      "  [253 253]\n",
      "  [253 198]\n",
      "  [ 81   2]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 18 171]\n",
      "  [219 253]\n",
      "  [253 253]\n",
      "  [253 195]\n",
      "  [ 80   9]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [ 55 172]\n",
      "  [226 253]\n",
      "  [253 253]\n",
      "  [253 244]\n",
      "  [133  11]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [136 253]\n",
      "  [253 253]\n",
      "  [212 135]\n",
      "  [132  16]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "codings_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 09:38:39.505892: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 14,2])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(input_shape):  \n",
    "    generator = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(96, 5, input_shape = input_shape, padding='same', activation='relu', name='conv1'),\n",
    "        keras.layers.Conv2D(96, 2, input_shape = input_shape, padding='same', activation='relu', name='conv2'),\n",
    "        keras.layers.Conv2D(96, 2, input_shape = input_shape, padding='same', activation='relu', name='conv3'),\n",
    "        keras.layers.Conv2D(96, 2, input_shape = input_shape, padding='same', activation='relu', name='conv4'),\n",
    "        keras.layers.MaxPool2D(pool_size=1, padding='same', name='pool4'),\n",
    "        keras.layers.Reshape([input_shape[0],None]),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(units=256, return_sequences=True), name='bi_lstm1'),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(units=256, return_sequences=True), name='bi_lstm2'),\n",
    "        keras.layers.Reshape([input_shape]),\n",
    "        \n",
    "    ])\n",
    "    generator.summary()\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape_13\" (type Reshape).\n\nTried to convert 'shape' to a tensor and failed. Error: None values not supported.\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 28, None, 96), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mRNN_GAN\u001b[39;00m \u001b[39mimport\u001b[39;00m make_discriminator\n\u001b[0;32m----> 2\u001b[0m generator \u001b[39m=\u001b[39m make_generator((\u001b[39m28\u001b[39;49m,\u001b[39mNone\u001b[39;49;00m,\u001b[39m2\u001b[39;49m))\n\u001b[1;32m      3\u001b[0m discriminator \u001b[39m=\u001b[39m make_discriminator((\u001b[39m28\u001b[39m,\u001b[39mNone\u001b[39;00m,\u001b[39m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m, in \u001b[0;36mmake_generator\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_generator\u001b[39m(input_shape):  \n\u001b[0;32m----> 2\u001b[0m     generator \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mSequential([\n\u001b[1;32m      3\u001b[0m         keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m96\u001b[39;49m, \u001b[39m5\u001b[39;49m, input_shape \u001b[39m=\u001b[39;49m input_shape, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv1\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      4\u001b[0m         keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m96\u001b[39;49m, \u001b[39m2\u001b[39;49m, input_shape \u001b[39m=\u001b[39;49m input_shape, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv2\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      5\u001b[0m         keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m96\u001b[39;49m, \u001b[39m2\u001b[39;49m, input_shape \u001b[39m=\u001b[39;49m input_shape, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv3\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      6\u001b[0m         keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m96\u001b[39;49m, \u001b[39m2\u001b[39;49m, input_shape \u001b[39m=\u001b[39;49m input_shape, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mconv4\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      7\u001b[0m         keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mMaxPool2D(pool_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpool4\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m      8\u001b[0m         keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mReshape([input_shape[\u001b[39m0\u001b[39;49m],\u001b[39mNone\u001b[39;49;00m]),\n\u001b[1;32m      9\u001b[0m         keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mBidirectional(keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mLSTM(units\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbi_lstm1\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     10\u001b[0m         keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mBidirectional(keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mLSTM(units\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbi_lstm2\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     11\u001b[0m         keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mReshape([input_shape]),\n\u001b[1;32m     12\u001b[0m         \n\u001b[1;32m     13\u001b[0m     ])\n\u001b[1;32m     14\u001b[0m     generator\u001b[39m.\u001b[39msummary()\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m generator\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/training/tracking/base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    630\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py:529\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    526\u001b[0m   observed \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    527\u001b[0m       values, as_ref\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mis_ref)\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname\n\u001b[1;32m    528\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 529\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    530\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTried to convert \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00minput_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to a tensor and failed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    531\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError: \u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    532\u001b[0m prefix \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m Op has type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m that does not match\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    533\u001b[0m           (input_name, op_type_name, observed))\n\u001b[1;32m    534\u001b[0m \u001b[39mif\u001b[39;00m input_arg\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m types_pb2\u001b[39m.\u001b[39mDT_INVALID:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_13\" (type Reshape).\n\nTried to convert 'shape' to a tensor and failed. Error: None values not supported.\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 28, None, 96), dtype=float32)"
     ]
    }
   ],
   "source": [
    "from RNN_GAN import make_discriminator\n",
    "generator = make_generator((28,None,2))\n",
    "discriminator = make_discriminator((28,None,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, None, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, None, 2), dtype=tf.float32, name='conv1_input'), name='conv1_input', description=\"created by layer 'conv1_input'\"), but it was called on an input with incompatible shape (None, 28, 512).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential_12\" (type Sequential).\n\nInput 0 of layer \"conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 28, 512)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 28, 512), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gan \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mSequential([generator, discriminator])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/training/tracking/base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    630\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/input_spec.py:228\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    226\u001b[0m   ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    227\u001b[0m   \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    230\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    231\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    232\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"sequential_12\" (type Sequential).\n\nInput 0 of layer \"conv1\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 28, 512)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 28, 512), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "discriminator.trainable = True\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "print(\"X_train type \" + str(type(X)))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.ShuffleDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     generated_images \u001b[39m=\u001b[39m generated_images\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mreshape(batch_size,\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m)\n\u001b[1;32m      6\u001b[0m     plot_multiple_images(generated_images, \u001b[39m8\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m makeImages()\n",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     generated_images \u001b[39m=\u001b[39m generated_images\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mreshape(batch_size,\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m)\n\u001b[1;32m      6\u001b[0m     plot_multiple_images(generated_images, \u001b[39m8\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m makeImages()\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def makeImages():\n",
    "    noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "    print(noise.shape)\n",
    "    generated_images = generator(noise)\n",
    "    generated_images = generated_images.numpy().reshape(batch_size,28,28)\n",
    "    plot_multiple_images(generated_images, 8)\n",
    "makeImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 2/20\n",
      "Epoch 3/20\n",
      "Epoch 4/20\n",
      "Epoch 5/20\n",
      "Epoch 6/20\n",
      "Epoch 7/20\n",
      "Epoch 8/20\n",
      "Epoch 9/20\n",
      "Epoch 10/20\n",
      "Epoch 11/20\n",
      "Epoch 12/20\n",
      "Epoch 13/20\n",
      "Epoch 14/20\n",
      "Epoch 15/20\n",
      "Epoch 16/20\n",
      "Epoch 17/20\n",
      "Epoch 18/20\n",
      "Epoch 19/20\n",
      "Epoch 20/20\n"
     ]
    }
   ],
   "source": [
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              # not shown in the book\n",
    "        for X_batch in dataset:\n",
    "            # phase 1 - training the discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)\n",
    "            X_batch = tf.cast(X_batch, tf.float32)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            # phase 2 - training the generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "            generated_images = generated_images.numpy().reshape(batch_size,28,28)\n",
    "            makeImages()                     # not shown\n",
    "            plt.show()\n",
    "train_gan(gan, dataset, batch_size, codings_size, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
