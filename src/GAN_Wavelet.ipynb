{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import Scalagram\n",
    "from Scalagram import Scalagram\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data/SwainsonCut.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_location \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./Data/SwainsonCut.wav\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m sg \u001b[39m=\u001b[39m Scalagram(file_location)\n\u001b[1;32m      3\u001b[0m image \u001b[39m=\u001b[39m sg\u001b[39m.\u001b[39mget_data()\n",
      "File \u001b[0;32m~/Desktop/Wavelet-Transform/src/Scalagram.py:15\u001b[0m, in \u001b[0;36mScalagram.__init__\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,file:\u001b[39mstr\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m## basically just the name of the file w/out the end or the beginning\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquality, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemp \u001b[39m=\u001b[39m get_wave_data(file)\n\u001b[1;32m     16\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfreqs,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m do_transform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquality, \u001b[39m1000\u001b[39m, \u001b[39m3\u001b[39m ,\u001b[39m25\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Wavelet-Transform/src/Scalagram.py:94\u001b[0m, in \u001b[0;36mget_wave_data\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_wave_data\u001b[39m(file:\u001b[39mstr\u001b[39m):\n\u001b[0;32m---> 94\u001b[0m     w \u001b[39m=\u001b[39m wave\u001b[39m.\u001b[39;49mopen(file,\u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     96\u001b[0m     num_frames \u001b[39m=\u001b[39m w\u001b[39m.\u001b[39mgetnframes()\n\u001b[1;32m     97\u001b[0m     width \u001b[39m=\u001b[39m w\u001b[39m.\u001b[39mgetsampwidth()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/wave.py:509\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    507\u001b[0m         mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 509\u001b[0m     \u001b[39mreturn\u001b[39;00m Wave_read(f)\n\u001b[1;32m    510\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m Wave_write(f)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/wave.py:159\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_i_opened_the_file \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 159\u001b[0m     f \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_i_opened_the_file \u001b[39m=\u001b[39m f\n\u001b[1;32m    161\u001b[0m \u001b[39m# else, assume it is an open file object already\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data/SwainsonCut.wav'"
     ]
    }
   ],
   "source": [
    "file_location = \"../Data/SwainsonCut.wav\"\n",
    "sg = Scalagram(file_location)\n",
    "image = sg.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_stupid_mnist import get_stupid_mnist\n",
    "X = get_stupid_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  3  18]\n",
      "  [ 18  18]\n",
      "  [126 136]\n",
      "  [175  26]\n",
      "  [166 255]\n",
      "  [247 127]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 30  36]\n",
      "  [ 94 154]\n",
      "  [170 253]\n",
      "  [253 253]\n",
      "  [253 253]\n",
      "  [225 172]\n",
      "  [253 242]\n",
      "  [195  64]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  49]\n",
      "  [238 253]\n",
      "  [253 253]\n",
      "  [253 253]\n",
      "  [253 253]\n",
      "  [253 251]\n",
      "  [ 93  82]\n",
      "  [ 82  56]\n",
      "  [ 39   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  18]\n",
      "  [219 253]\n",
      "  [253 253]\n",
      "  [253 253]\n",
      "  [198 182]\n",
      "  [247 241]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 80 156]\n",
      "  [107 253]\n",
      "  [253 205]\n",
      "  [ 11   0]\n",
      "  [ 43 154]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  14]\n",
      "  [  1 154]\n",
      "  [253  90]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0 139]\n",
      "  [253 190]\n",
      "  [  2   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  11]\n",
      "  [190 253]\n",
      "  [ 70   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 35 241]\n",
      "  [225 160]\n",
      "  [108   1]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  81]\n",
      "  [240 253]\n",
      "  [253 119]\n",
      "  [ 25   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 45 186]\n",
      "  [253 253]\n",
      "  [150  27]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0  16]\n",
      "  [ 93 252]\n",
      "  [253 187]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0 249]\n",
      "  [253 249]\n",
      "  [ 64   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 46 130]\n",
      "  [183 253]\n",
      "  [253 207]\n",
      "  [  2   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 39 148]\n",
      "  [229 253]\n",
      "  [253 253]\n",
      "  [250 182]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 24 114]\n",
      "  [221 253]\n",
      "  [253 253]\n",
      "  [253 201]\n",
      "  [ 78   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 23  66]\n",
      "  [213 253]\n",
      "  [253 253]\n",
      "  [253 198]\n",
      "  [ 81   2]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [ 18 171]\n",
      "  [219 253]\n",
      "  [253 253]\n",
      "  [253 195]\n",
      "  [ 80   9]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [ 55 172]\n",
      "  [226 253]\n",
      "  [253 253]\n",
      "  [253 244]\n",
      "  [133  11]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [136 253]\n",
      "  [253 253]\n",
      "  [212 135]\n",
      "  [132  16]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]\n",
      "\n",
      " [[  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]\n",
      "  [  0   0]]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "codings_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 11:04:43.987597: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 14,2])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(input_shape):  \n",
    "    generator = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(96, 5, input_shape = input_shape, padding='same', activation='relu', name='conv1'),\n",
    "        keras.layers.Conv2D(96, 2, input_shape = input_shape, padding='same', activation='relu', name='conv2'),\n",
    "        keras.layers.Conv2D(96, 2, input_shape = input_shape, padding='same', activation='relu', name='conv3'),\n",
    "        keras.layers.Conv2D(96, 2, input_shape = input_shape, padding='same', activation='relu', name='conv4'),\n",
    "        keras.layers.MaxPool2D(pool_size=1, padding='same', name='pool4'),\n",
    "        keras.layers.Reshape([input_shape[0],None]),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(units=256, return_sequences=True), name='bi_lstm1'),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(units=256, return_sequences=True), name='bi_lstm2'),\n",
    "        keras.layers.Reshape([input_shape]),\n",
    "        \n",
    "    ])\n",
    "    generator.summary()\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GAN_DISC import build_discriminator, build_generator\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator((28,None,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, None, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, None, 2), dtype=tf.float32, name='disc_input'), name='disc_input', description=\"created by layer 'disc_input'\"), but it was called on an input with incompatible shape (None, 64, None, 2).\n"
     ]
    }
   ],
   "source": [
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "discriminator.trainable = True\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train type <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "print(\"X_train type \" + str(type(X)))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.ShuffleDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 30)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     generated_images \u001b[39m=\u001b[39m generated_images\u001b[39m.\u001b[39mreshape(batch_size,\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m)\n\u001b[1;32m     20\u001b[0m     plot_multiple_images(generated_images, \u001b[39m8\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m makeImages()\n",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m, in \u001b[0;36mmakeImages\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     elem \u001b[39m=\u001b[39m image\n\u001b[1;32m     16\u001b[0m     generated_images \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m image\n\u001b[0;32m---> 17\u001b[0m print_function(generated_images[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     18\u001b[0m generated_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mndarray(generated_images)\n\u001b[1;32m     19\u001b[0m generated_images \u001b[39m=\u001b[39m generated_images\u001b[39m.\u001b[39mreshape(batch_size,\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def makeImages():\n",
    "    noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "    print(noise.shape)\n",
    "    #generated_images = generator(noise)\n",
    "    #generated_images = generated_images.numpy().reshape(batch_size,28,28)\n",
    "    \n",
    "    generated_images = []\n",
    "        # 1.0 will be printed.\n",
    "    counter = 0\n",
    "    elem = None\n",
    "    for image in dataset:\n",
    "        if counter >= batch_size:\n",
    "            break\n",
    "        counter+= 1\n",
    "        elem = image\n",
    "        generated_images += image\n",
    "    print_function(generated_images[0].shape)\n",
    "    generated_images = np.ndarray(generated_images)\n",
    "    generated_images = generated_images.reshape(batch_size,28,28)\n",
    "    plot_multiple_images(generated_images, 8)\n",
    "makeImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Epoch 2/20\n",
      "Epoch 3/20\n",
      "Epoch 4/20\n",
      "Epoch 5/20\n",
      "Epoch 6/20\n",
      "Epoch 7/20\n",
      "Epoch 8/20\n",
      "Epoch 9/20\n",
      "Epoch 10/20\n",
      "Epoch 11/20\n",
      "Epoch 12/20\n",
      "Epoch 13/20\n",
      "Epoch 14/20\n",
      "Epoch 15/20\n",
      "Epoch 16/20\n",
      "Epoch 17/20\n",
      "Epoch 18/20\n",
      "Epoch 19/20\n",
      "Epoch 20/20\n"
     ]
    }
   ],
   "source": [
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              # not shown in the book\n",
    "        for X_batch in dataset:\n",
    "            # phase 1 - training the discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)\n",
    "            X_batch = tf.cast(X_batch, tf.float32)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            # phase 2 - training the generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "            generated_images = generated_images.numpy().reshape(batch_size,28,28)\n",
    "            makeImages()                     # not shown\n",
    "            plt.show()\n",
    "train_gan(gan, dataset, batch_size, codings_size, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
